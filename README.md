üèÄ Pipeline de An√°lisis y Predicci√≥n NBA con Kedro
üìã Descripci√≥n del Proyecto
Este proyecto analiza datos de la NBA para identificar patrones de rendimiento de equipos y genera modelos de machine learning para predecir resultados de partidos.
Utiliza el framework Kedro para crear pipelines reproducibles y modulares, integrando DVC para control de versiones de datos, Airflow para orquestaci√≥n, y Docker para containerizaci√≥n.

üéØ Objetivos Principales
üìå Identificar qu√© equipos son mejores jugando en casa

üìå Analizar qu√© equipos son peores como visitantes

üìå Predecir si el equipo local ganar√° (Clasificaci√≥n)

üìå Predecir m√©tricas de rendimiento (Regresi√≥n):

local_strength: Fuerza del equipo local

away_weakness: Debilidad del equipo visitante

point_differential: Diferencia de puntos

home_advantage: Ventaja de jugar en casa

üìå Crear pipelines modulares y reproducibles

ü§ñ Modelos de Machine Learning
üéØ Modelo de Clasificaci√≥n
Objetivo: Predecir si el equipo local ganar√° el partido

Algoritmos implementados:

Logistic Regression

Decision Tree Classifier

Random Forest Classifier

Support Vector Machine (SVC)

Gaussian Naive Bayes

Caracter√≠sticas principales:

Tasas de victoria hist√≥ricas (local/visitante)

Rendimiento reciente (√∫ltimos 10 partidos)

M√©tricas de fuerza del equipo

Historial de enfrentamientos

M√©tricas de evaluaci√≥n:

Precisi√≥n (Accuracy)

Precisi√≥n (Precision)

Recall

Puntuaci√≥n F1

ROC-AUC

üìà Modelo de Regresi√≥n
Objetivo: Predecir m√©tricas continuas de rendimiento

Variables objetivo:

local_strength: Puntuaci√≥n de fuerza del equipo local (0-100)

away_weakness: √çndice de debilidad del visitante (0-100)

point_differential: Diferencia esperada de puntos (¬±)

home_advantage: Ventaja por jugar en casa (0-20)

M√©tricas de evaluaci√≥n:

RMSE (Error Cuadr√°tico Medio)

MAE (Error Absoluto Medio)

Puntuaci√≥n R¬≤

üöÄ Inicio R√°pido
Prerrequisitos
Python 3.8+

Docker y Docker Compose

Git

Opci√≥n 1: Docker (Recomendada)

# Clonar repositorio
git clone <url-del-repositorio>
cd nba-analysis

# Construir y ejecutar con Docker
docker-compose up --build

# Acceder a los servicios:
# Airflow: http://localhost:8080 (usuario: airflow, contrase√±a: airflow)
# Kedro Viz: http://localhost:4141

Opci√≥n 2: Desarrollo Local
# Clonar y configurar
git clone <url-del-repositorio>
cd nba-analysis

# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate  # Windows

# Instalar dependencias
pip install -r requirements.txt

# Configurar datos
mkdir -p data/01_raw
# Colocar datasets en data/01_raw/

# Inicializar DVC
dvc init

# Ejecutar pipeline
kedro run

üìä Datasets Utilizados
El proyecto utiliza 3 datasets principales de Kaggle (NBA Games):

Dataset	Descripci√≥n
games.csv	Resultados y estad√≠sticas de partidos
games_details.csv	Estad√≠sticas por jugador por partido
teams.csv	Informaci√≥n de los equipos
Fuente: Kaggle - NBA Games Dataset

üê≥ Configuraci√≥n de Docker
Construir y Ejecutar
# Construir im√°genes
docker-compose build

# Ejecutar todos los servicios
docker-compose up -d

# Ver logs
docker-compose logs -f

# Detener servicios
docker-compose down

Resumen de Servicios
Servicio	Puerto	Prop√≥sito
Pipeline Kedro	-	Procesamiento de datos y entrenamiento de modelos
Airflow	8080	Orquestaci√≥n de pipelines
Kedro Viz	4141	Visualizaci√≥n de pipelines

Comandos √ötiles de Docker

# Ejecutar comandos espec√≠ficos
docker-compose run app kedro run
docker-compose run app kedro test

# Acceder a la shell del contenedor
docker-compose exec app bash

# Ver logs de servicios espec√≠ficos
docker-compose logs -f app

üå™Ô∏è Orquestaci√≥n con Airflow

Iniciar Airflow

# Usando Docker Compose
docker-compose -f docker-compose-airflow.yml up -d

# Acceder a la interfaz web: http://localhost:8080
# Usuario: airflow, Contrase√±a: airflow

DAG Principal - Pipeline NBA
El DAG de Airflow ejecuta autom√°ticamente:

1.Preprocesamiento de datos y validaci√≥n

2.Entrenamiento de modelos (clasificaci√≥n y regresi√≥n)

3.Evaluaci√≥n de modelos y c√°lculo de m√©tricas

4.Generaci√≥n de predicciones y reportes

Comandos de Airflow

# Listar DAGs
docker-compose -f docker-compose-airflow.yml exec webserver airflow dags list

# Ejecutar DAG manualmente
docker-compose -f docker-compose-airflow.yml exec webserver airflow dags trigger nba_pipeline

# Ver estado de tareas
docker-compose -f docker-compose-airflow.yml exec webserver airflow tasks list nba_pipeline

üìä DVC (Control de Versiones de Datos)

Configuraci√≥n Inicial

# Inicializar DVC
dvc init

# Configurar almacenamiento remoto (ejemplo local)
dvc remote add -d myremote /ruta/al/almacenamiento

# Para almacenamiento en la nube (ejemplo AWS S3):
dvc remote add -d myremote s3://mi-bucket/nba-data

Flujo de Trabajo con DVC

# A√±adir datasets al seguimiento de DVC
dvc add data/01_raw/games.csv
dvc add data/01_raw/games_details.csv
dvc add data/01_raw/teams.csv

# A√±adir modelos al seguimiento
dvc add models/classification_model.pkl
dvc add models/regression_model.pkl

# Hacer commit en Git
git add .dvc data/01_raw/.gitignore models/.gitignore
git commit -m "A√±adir datasets y modelos a DVC"

Flujo de Trabajo Diario

# Obtener datos m√°s recientes
dvc pull

# Ejecutar pipeline
kedro run

# A√±adir nuevos resultados a DVC
dvc add data/06_models/predictions.csv
dvc add models/

# Subir cambios al almacenamiento remoto
dvc push

# Hacer commit de cambios de metadatos
git add .dvc
git commit -m "Actualizar modelos y predicciones"
git push

Reproducir Experimentos

# Reproducir pipeline espec√≠fico
dvc repro pipelines/data_processing

# Verificar estado
dvc status

# Comparar m√©tricas entre versiones
dvc metrics diff

üèÉ‚Äç‚ôÇÔ∏è Ejecuci√≥n del Proyecto

Pipeline Completo

# Usando Kedro directamente
kedro run

# Usando Docker
docker-compose run app kedro run

# Usando Airflow
# Activar el DAG nba_pipeline en la interfaz de Airflow

Pipelines Espec√≠ficos

# Solo procesamiento de datos
kedro run --pipeline=data_engineering


# Solo entrenamiento de clasificaci√≥n
kedro run --pipeline=classification

# Solo entrenamiento de regresi√≥n
kedro run --pipeline=regression

Visualizaci√≥n y An√°lisis

# Visualizaci√≥n del pipeline
kedro viz
# Acceder: http://localhost:4141

# Notebooks Jupyter con contexto de Kedro
kedro jupyter notebook

# Notebook de an√°lisis espec√≠fico
kedro jupyter notebook --notebook-path notebooks/04_model_analysis.ipynb

üîß Comandos √ötiles
Informaci√≥n del Proyecto

# Resumen del proyecto
kedro info

# Listar datasets disponibles
kedro catalog list

# Ejecutar tests
kedro test

# Crear nuevo pipeline
kedro pipeline create <nombre_pipeline>

Gesti√≥n de Servicios

# Iniciar todos los servicios
docker-compose up -d

# Detener todos los servicios
docker-compose down

# Verificar estado de servicios
docker-compose ps

# Ver logs de servicios
docker-compose logs -f <nombre_servicio>

Gesti√≥n de Datos y Modelos

# Verificar estado de DVC
dvc status

# Obtener datos m√°s recientes
dvc pull

# Subir cambios al remoto
dvc push

# Reproducir pipeline
dvc repro